{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook investigates different methods of image similarity measurements to find near-duplicate images. These images can help improve the aesthetic training by filtering out (near-) duplicate images that may have contradictory star-ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import exifread\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import glob\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "from measure_img_similarity import earth_movers_distance, structural_sim, pixel_sim\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to assess all possible image combinations from a given file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/keras/dev/pictures_per_usecase/Ralf_Wieting_Moments/2016-07-10 Binz/moment19/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we measure the image similarity using different methods (EMD, structural similarity, etc.).  \n",
    "We also measure the execution time both for a single combination and for all images.  \n",
    "To decrease the execution time we can change the resolution in measure_img_similarity.py. Also we only compare the combinations that are less than 30 seconds apart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from os import walk, path\n",
    "import math\n",
    "\n",
    "def get_timestamp_difference(image_a, image_b):\n",
    "    tags_image_1 = {}\n",
    "    tags_image_2 = {}\n",
    "    with open(image_a, 'rb') as f:\n",
    "        tags_image_1 = exifread.process_file(f, details=False)\n",
    "    with open(image_b, 'rb') as f:\n",
    "        tags_image_2 = exifread.process_file(f, details=False)\n",
    "    \n",
    "    if \"Image DateTime\" in tags_image_1.keys() and \"Image DateTime\" in tags_image_2.keys():\n",
    "        datetime_1 = str(tags_image_1[\"Image DateTime\"]).split(\".\")[0]\n",
    "        datetime_2 = str(tags_image_2[\"Image DateTime\"]).split(\".\")[0]\n",
    "        \n",
    "        dt_obj_1 = datetime.strptime(datetime_1, '%Y:%m:%d %H:%M:%S')\n",
    "        dt_obj_2 = datetime.strptime(datetime_2, '%Y:%m:%d %H:%M:%S')\n",
    "\n",
    "        millisec_1 = dt_obj_1.timestamp() * 1000\n",
    "        millisec_2 = dt_obj_2.timestamp() * 1000\n",
    "\n",
    "        return abs(millisec_2 - millisec_1)\n",
    "    \n",
    "    else:\n",
    "        print(\"No timestamp in one of the images\")\n",
    "        return math.inf\n",
    "\n",
    "'''Calculates the SSIM for all image combinations within a given directory.\n",
    "   Only combinations that are less than or equal to 30000 miliseconds apart are considered.'''\n",
    "\n",
    "def calculate_SSIM_for_directory(directory_name, allowed_seconds_between_images=30):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in walk(directory_name):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    \n",
    "    f = [path.join(directory_name, x) for x in f]\n",
    "    \n",
    "    image_filenames = f\n",
    "    \n",
    "    #print(image_filenames)\n",
    "    \n",
    "    if len(image_filenames) > 1:\n",
    "        possible_combinations = list(itertools.combinations(image_filenames, 2))\n",
    "\n",
    "        list_of_dicts = []\n",
    "        dict_combination_ssim = {}\n",
    "\n",
    "        time_total_1 = time.time()\n",
    "        for combination in possible_combinations:\n",
    "            time_single_1 = time.time()\n",
    "            #emd = earth_movers_distance(path_a=combination[0], path_b=combination[1])\n",
    "            if get_timestamp_difference(combination[0], combination[1]) <= allowed_seconds_between_images*1000:\n",
    "                \n",
    "                struct_sim = structural_sim(path_a=combination[0], path_b=combination[1])\n",
    "                pixel_similarity = pixel_sim(path_a=combination[0], path_b=combination[1])\n",
    "                time_single_2 = time.time()\n",
    "                time_single_total = time_single_2 - time_single_1\n",
    "\n",
    "                dict_combination_ssim = {\"image_path_1\" : combination[0], \n",
    "                                         \"image_path_2\" : combination[1], \n",
    "                                         \"struct_sim\" : struct_sim,\n",
    "                                         \"pixel_sim\" : pixel_similarity}\n",
    "                list_of_dicts.append(dict_combination_ssim.copy())\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        time_total_2 = time.time()\n",
    "        time_total_passed = time_total_2 - time_total_1\n",
    "        return list_of_dicts\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(calculate_SSIM_for_directory(directory, allowed_seconds_between_images=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sort and display the top 10 combinations with the heighest similarity (for EMD it's the lowest values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dataframe = dataframe.sort_values([\"struct_sim\"], ascending=False)\n",
    "display(sorted_dataframe[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have the same length as titles.\n",
    "    \"\"\"\n",
    "    \n",
    "    generic_title = False\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: \n",
    "        titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "        generic_title = True\n",
    "        \n",
    "    best_image = \"\"\n",
    "    top_score = 0\n",
    "    \n",
    "    if type(titles[0]) is not str:\n",
    "        for n, (image, title) in enumerate(zip(images, titles)):\n",
    "            if title >= top_score:\n",
    "                top_score = title\n",
    "                best_image = image\n",
    "                \n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "           \n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        \n",
    "        '''If scores are provides as titles for the images, we mark the best with a green border'''\n",
    "        if image == best_image:\n",
    "            img = cv2.imread(image)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # border color\n",
    "            color = [58, 255, 81]\n",
    "            \n",
    "            # border widths\n",
    "            top, bottom, left, right = [25] * 4\n",
    "            \n",
    "            img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "        \n",
    "        else:\n",
    "            img = Image.open(image)\n",
    "            \n",
    "        #img = img.resize((512, 512))\n",
    "        img = np.asarray(img)\n",
    "        \n",
    "        if img.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(img)\n",
    "        if generic_title == False and type(title) is str:\n",
    "            title = title.split('/')[8]\n",
    "        a.set_title(title)\n",
    "        \n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a threshold to assess when two images are (very) similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_duplicate_dataframe(sorted_dataframe, threshold = 0.15):\n",
    "    duplicates_dataframe = pd.DataFrame(columns=[\"image_path_1\", \"image_path_2\", \"struct_sim\", \"pixel_sim\"])\n",
    "\n",
    "    i = 0\n",
    "    for row in sorted_dataframe.iterrows():\n",
    "        if row[1][\"struct_sim\"] >= threshold:\n",
    "            show_images([row[1][\"image_path_1\"], row[1][\"image_path_2\"]])\n",
    "            duplicates_dataframe.loc[i] = [row[1][\"image_path_1\"], row[1][\"image_path_2\"], row[1][\"struct_sim\"], row[1][\"pixel_sim\"]]\n",
    "            i += 1\n",
    "            \n",
    "    return duplicates_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_dataframe = reduce_duplicate_dataframe(sorted_dataframe, threshold=0.15)\n",
    "display(duplicates_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that duplicates are found effectively but some pictures are presented multiple times.  \n",
    "We need to create \"duplicate clusters\" that represent batches of similar images rather than just have tuples of images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicateCluster(object):\n",
    "        \n",
    "    def __init__(self, index_image_path):\n",
    "        self.index_image_path = index_image_path\n",
    "        self.similar_images = []\n",
    "    \n",
    "    def appendImagePath(self, imagePath):\n",
    "        self.similar_images.append(imagePath)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_picture_in_other_cluster(list_of_clusters, image_filepath):\n",
    "    entry_exists = False\n",
    "    for cluster in list_of_clusters:\n",
    "        if image_filepath in cluster.similar_images or image_filepath == cluster.index_image_path:\n",
    "            entry_exists = True\n",
    "    return entry_exists\n",
    "\n",
    "def create_image_clusters(duplicates_dataframe):\n",
    "    cluster_list = []\n",
    "    for row in duplicates_dataframe.iterrows():\n",
    "        image_path_exists_as_index = False\n",
    "\n",
    "        filepath_image_a = row[1][\"image_path_1\"]\n",
    "        filepath_image_b = row[1][\"image_path_2\"]\n",
    "\n",
    "        if len(cluster_list) >= 1: \n",
    "            for cluster in cluster_list:\n",
    "                if filepath_image_a == cluster.index_image_path:\n",
    "                    image_path_exists_as_index = True\n",
    "                    if check_if_picture_in_other_cluster(cluster_list, filepath_image_b) == False:\n",
    "                        cluster.appendImagePath(filepath_image_b)\n",
    "                elif filepath_image_b == cluster.index_image_path:\n",
    "                    image_path_exists_as_index = True\n",
    "                    if check_if_picture_in_other_cluster(cluster_list, filepath_image_a) == False:\n",
    "                        cluster.appendImagePath(filepath_image_a)\n",
    "\n",
    "        if check_if_picture_in_other_cluster(cluster_list, filepath_image_a) == False or len(cluster_list) == 0:\n",
    "            cluster_to_add = DuplicateCluster(filepath_image_a)\n",
    "            if check_if_picture_in_other_cluster(cluster_list, filepath_image_b) == False:\n",
    "                cluster_to_add.appendImagePath(filepath_image_b)\n",
    "            cluster_list.append(cluster_to_add)\n",
    "\n",
    "    return cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_list = create_image_clusters(duplicates_dataframe)\n",
    "i = 1\n",
    "for e in cluster_list:\n",
    "    #print(e.__dict__)\n",
    "    image_list = [e.index_image_path, *(e.similar_images)]\n",
    "    show_images(image_list, titles=image_list)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preventing the near-duplicate clustering from having images allocated to multiple clusters we now need to allocate the clusters where only one image is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_to_existing_cluster(cluster_list, filepath):\n",
    "    reference_cluster = None\n",
    "    ssim = 0.0\n",
    "    for cluster in cluster_list:\n",
    "        # Skip the cluster that this image belongs to\n",
    "        if cluster.index_image_path == filepath:\n",
    "            continue\n",
    "        # Calculate structural similarity for each cluster-index-image to find the one that matches the best   \n",
    "        temp_ssim = structural_sim(cluster.index_image_path, filepath)\n",
    "        if temp_ssim >= ssim:\n",
    "            ssim = temp_ssim\n",
    "            reference_cluster = cluster\n",
    "    if ssim >= 0.2:\n",
    "        reference_cluster.appendImagePath(filepath)\n",
    "\n",
    "def reallocate_single_images(cluster_list):\n",
    "    for cluster in cluster_list:\n",
    "        # Find images with no corresponding similar images \n",
    "        if len(cluster.similar_images ) == 0:\n",
    "            # Add them to another cluster and delete the now redundant cluster-object\n",
    "            add_image_to_existing_cluster(cluster_list, cluster.index_image_path)\n",
    "            cluster_list.remove(cluster)\n",
    "    return cluster_list\n",
    "\n",
    "def print_image_clusters(cluster_list):\n",
    "    i = 1\n",
    "    for e in cluster_list:\n",
    "        score_list = []\n",
    "        image_list = [e.index_image_path, *(e.similar_images)]\n",
    "        for image in image_list:\n",
    "            score_list.append(get_model_score(image))\n",
    "        print(\"\\n\")\n",
    "        show_images(image_list, titles=score_list)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image_clusters(reallocate_single_images(cluster_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate aesthetic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras_applications.mobilenet import relu6, preprocess_input\n",
    "\n",
    "cewe_model = load_model(\"/home/keras/dev/trained_models/cewe_binary_scoring/cewe_binary_scoring_ava_pretrained.h5\", \n",
    "                        custom_objects={\"relu6\" : relu6})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To check which image to \"keep\" from the duplicate cluster we predict the aesthetics score with the deep learning model'''\n",
    "\n",
    "def get_model_score(image_filename):\n",
    "    img = load_img(image_filename, target_size=(224, 224))\n",
    "    \n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    x = preprocess_input(img_array)\n",
    "    \n",
    "    return cewe_model.predict(x)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - Deep Learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import double_channel_network.inception_double_channel_color as inception_double_channel_color\n",
    "\n",
    "images = []\n",
    "for i, f in enumerate(image_filenames):\n",
    "    img = io.imread(f)\n",
    "    img = transform.resize(img, (96, 96))\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception_double_channel_color.create_model()\n",
    "model.load_weights('double_channel_network/double_channel_color_inception_95.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Single test:\n",
    "time_before = time.time()\n",
    "result = model.predict(np.dstack((images[5], images[2])).reshape((1,96,96,6)))\n",
    "time_after = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_after-time_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_predictions = []\n",
    "single_entry = {}\n",
    "\n",
    "threshold = 0.999999999\n",
    "i = 0\n",
    "for combi in itertools.combinations(images, 2):\n",
    "    prediction = model.predict(np.dstack((combi[0], combi[1])).reshape((1,96,96,6)))\n",
    "    if prediction[0][0] >= threshold and prediction[0][1] < 1-threshold:\n",
    "        plt.imshow(combi[0])\n",
    "        plt.show()\n",
    "        plt.imshow(combi[1])\n",
    "        plt.show()\n",
    "        \n",
    "#         single_entry = {\"image_1\" : i, \"image_2\" : i+1, \"prediction\" : prediction[0][0]} \n",
    "#         calculated_predictions.append(single_entry.copy())\n",
    "#         i += 1\n",
    "\n",
    "#print(len(calculated_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next step:**  \n",
    "Now that we have a good solution for detecting near-duplicate images and sorted them into clusters we can use the information to improve the training of our deep learning aesthetics model.  \n",
    "For each duplicate cluster one image is taken with the best star rating. This image is then used for training (in combination with all the other non duplicate images).  \n",
    "\n",
    "**Repeat for all \"moments\":**  \n",
    "* 1.: Calculate near-duplicate cluster for given images\n",
    "* 2.: Create a list where each cluster is on the same level (as opposed to a single index-image and several similar images in a list)\n",
    "* 3.: Get the best image for each cluster with the list created in 2.\n",
    "* 4.: Define the non-duplicate images by subtractinc all images in the moment by the list created in 2.\n",
    "* 5.: Get a dictionary with the filepath and the star-rating for the non-duplicate images\n",
    "* 6.: Combine the result of step 3. with the images from step 5. to get a final dictionary for each moment. Save this dataframe to a .csv file\n",
    "\n",
    "The last step is to iterate over every .csv file created in 6 and combine them into a single dataframe that can be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n",
    "def get_rating_for_non_duplicates(non_duplicates):\n",
    "    list_of_dicts = []\n",
    "       \n",
    "    for image in non_duplicates:\n",
    "        single_entry = {}\n",
    "        file = open(image, 'rb')\n",
    "        tags = exifread.process_file(file)\n",
    "        if \"Image Rating\" in tags.keys():\n",
    "            single_entry = {\"filepath\" : image, \"star_rating\" : tags[\"Image Rating\"]}\n",
    "            list_of_dicts.append(single_entry.copy())\n",
    "        else: \n",
    "            print(\"No rating for image!\")\n",
    "            continue\n",
    "\n",
    "    non_duplicate_dataframe = pd.DataFrame(list_of_dicts)\n",
    "    return non_duplicate_dataframe\n",
    "\n",
    "# 3.\n",
    "def get_best_images_from_clusters(final_cluster_list):\n",
    "    best_images = []\n",
    "    for c in final_cluster_list:\n",
    "        single_entry = {}\n",
    "        list_to_check = []\n",
    "        best_image_of_cluster = \"\"\n",
    "        list_to_check = [c.index_image_path, *(c.similar_images)]\n",
    "        for image in list_to_check:\n",
    "            temp_rating = 0\n",
    "            file = open(image, 'rb')\n",
    "            tags = exifread.process_file(file)\n",
    "            if \"Image Rating\" in tags.keys():\n",
    "                if int(str(tags[\"Image Rating\"])) >= temp_rating:\n",
    "                    temp_rating = tags[\"Image Rating\"]\n",
    "            else:\n",
    "                continue\n",
    "        single_entry = {\"filepath\" : image, \"star_rating\" : temp_rating}\n",
    "        best_images.append(single_entry.copy())\n",
    "    return best_images\n",
    "\n",
    "# 2.\n",
    "def create_same_level_list(final_cluster_list):\n",
    "    image_cluster_as_list = []\n",
    "    for e in final_cluster_list:\n",
    "        image_cluster_as_list.append(e.index_image_path)\n",
    "        for s_img in e.similar_images:\n",
    "            image_cluster_as_list.append(s_img)\n",
    "    \n",
    "    return image_cluster_as_list\n",
    "\n",
    "# 1.\n",
    "def calculate_clusters_for_all_moments(directory):\n",
    "    #print(directory)\n",
    "    list_of_dicts = calculate_SSIM_for_directory(directory)\n",
    "    if list_of_dicts != None and len(list_of_dicts) != 0:\n",
    "        dataframe = pd.DataFrame(list_of_dicts)\n",
    "        sorted_dataframe = dataframe.sort_values([\"struct_sim\"], ascending=False)\n",
    "\n",
    "        reduced_dataframe = reduce_duplicate_dataframe(sorted_dataframe=sorted_dataframe, threshold=0.15)\n",
    "        cluster_list = create_image_clusters(reduced_dataframe)\n",
    "        final_cluster_list = reallocate_single_images(cluster_list)\n",
    "\n",
    "        return final_cluster_list\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test output:\n",
    "\n",
    "list_of_dicts = calculate_SSIM_for_directory(\"/home/keras/dev/pictures_per_usecase/Ralf_Wieting_Moments/2018-04-01 Ostern/moment1\", allowed_seconds_between_images=30)\n",
    "\n",
    "dataframe = pd.DataFrame(list_of_dicts)\n",
    "sorted_dataframe = dataframe.sort_values([\"struct_sim\"], ascending=False)\n",
    "\n",
    "reduced_dataframe = reduce_duplicate_dataframe(sorted_dataframe=sorted_dataframe, threshold=0.05)\n",
    "cluster_list = create_image_clusters(reduced_dataframe)\n",
    "final_cluster_list = reallocate_single_images(cluster_list)\n",
    "\n",
    "print_image_clusters(final_cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = \"/home/keras/dev/pictures_per_usecase/Ralf_Wieting_Moments/*/*\"\n",
    "\n",
    "'''For every moment we calculate the duplicate clusters, get the best image out of each cluster and \n",
    "   define the non-duplicate images. A combination of the latter two is used to create a dataframe \n",
    "   which is saved to a .csv file. '''\n",
    "\n",
    "i = 0\n",
    "sub_directory_list = glob.glob(parent_directory)\n",
    "for sub_directory in sub_directory_list:\n",
    "    print(i)\n",
    "    final_cluster_list = calculate_clusters_for_all_moments(sub_directory)\n",
    "    if final_cluster_list != None:\n",
    "        image_cluster_as_list = create_same_level_list(final_cluster_list)     \n",
    "        best_images = get_best_images_from_clusters(final_cluster_list)\n",
    "        best_images_dataframe = pd.DataFrame(best_images)\n",
    "    else:\n",
    "        image_cluster_as_list = []\n",
    "    \n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in walk(sub_directory):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    \n",
    "    f = [path.join(sub_directory, x) for x in f]\n",
    "    \n",
    "    all_filenames = f\n",
    "    non_duplicates = list(set(all_filenames) - set(image_cluster_as_list))\n",
    "    non_duplicate_dataframe = get_rating_for_non_duplicates(non_duplicates)\n",
    "\n",
    "    frames = [best_images_dataframe, non_duplicate_dataframe]\n",
    "    result = pd.concat(frames)\n",
    "    result.reset_index(inplace=True, drop=True)\n",
    "    result.to_csv(\"duplicate_free_images_\" + str(i) + \".csv\", decimal=\".\", sep=\";\", index=False)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **last step** is to create one Dataframe that contains every image filepath and its star-rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=\";\", decimal=\".\")\n",
    "        overall_data = overall_data.append(df, ignore_index=True)\n",
    "    \n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "display(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data.to_csv(\"duplicate_free_images_with_rating.csv\", sep=\";\", decimal=\".\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
